# 如何優化 Django 查詢性能 (QuerySet Optimization)？

- **難度**: 7
- **標籤**: `Django`, `ORM`, `Performance`, `Database`

## 問題詳述

在 Django 應用中，低效的資料庫查詢是造成性能問題的主要原因之一。如何有效優化 Django 的 QuerySet 查詢，避免常見的性能陷阱？

## 核心理論與詳解

### N+1 查詢問題及解決方案

**N+1 問題**是最常見的 ORM 性能陷阱：
- **問題來源**：在循環中訪問關聯對象，導致每次迭代都觸發額外的資料庫查詢
- **範例場景**：查詢所有文章及其作者資訊時，如果不優化，會產生 1 次查詢文章 + N 次查詢作者（N 為文章數量）

**解決方案 - select_related()**：
- 用於 **ForeignKey** 和 **OneToOne** 關係
- 使用 SQL JOIN 在單次查詢中獲取關聯資料
- 適用於「一對一」或「多對一」關係
- **原理**：在 SQL 層面使用 INNER JOIN 或 LEFT OUTER JOIN 合併查詢

**解決方案 - prefetch_related()**：
- 用於 **ManyToMany** 和反向 **ForeignKey** 關係
- 執行額外的查詢並在 Python 層面進行關聯
- 適用於「一對多」或「多對多」關係
- **原理**：執行兩次獨立查詢，然後在應用層做 JOIN

### 查詢集優化技巧

**1. 只查詢需要的欄位**
- `values()` / `values_list()`：返回字典或元組，減少記憶體使用
- `only()`：延遲載入指定欄位以外的欄位
- `defer()`：延遲載入指定的欄位
- **使用時機**：當只需要少數欄位時，可顯著減少資料傳輸量

**2. 使用 exists() 和 count()**
- `exists()`：檢查是否存在記錄，比 `len(queryset)` 或 `queryset.count()` 更快
- `count()`：獲取數量時使用，避免將所有資料載入記憶體
- **原理**：在資料庫層面執行 COUNT() 或 EXISTS 查詢

**3. 批量操作**
- `bulk_create()`：批量建立對象，避免多次 INSERT
- `bulk_update()`：批量更新對象
- `update()`：直接在資料庫層面更新，跳過模型層
- **優勢**：減少資料庫往返次數，顯著提升性能

### 查詢集緩存機制

**QuerySet 的惰性求值**：
- QuerySet 在真正需要資料時才執行查詢（如迭代、切片、序列化時）
- 重複使用同一個 QuerySet 會重用緩存結果
- **注意事項**：切片操作和某些方法會觸發新查詢

**緩存策略**：
- 將 QuerySet 賦值給變數以重用結果
- 使用 `iterator()` 處理大量資料，節省記憶體但失去緩存
- 使用 `Prefetch` 對象進行更精細的預取控制

### 資料庫索引

**創建適當的索引**：
- 在 Model 的 Meta 類中使用 `indexes` 定義索引
- 對頻繁查詢的欄位（如 `filter()`、`order_by()` 使用的欄位）建立索引
- **複合索引**：對多欄位查詢條件建立聯合索引
- **注意**：過多索引會影響寫入性能

**db_index 選項**：
- 在欄位定義中設置 `db_index=True`
- 自動為該欄位建立單欄位索引

### 資料庫查詢分析工具

**Django Debug Toolbar**：
- 顯示每個請求執行的 SQL 查詢
- 識別重複查詢和慢查詢
- 提供查詢執行時間分析

**connection.queries**：
- 在 DEBUG 模式下記錄所有執行的查詢
- 用於測試和開發環境的性能分析

**explain() 方法**：
- Django 2.1+ 支援
- 顯示查詢的執行計劃
- 幫助理解資料庫如何執行查詢

### 進階優化技巧

**1. 使用 Subquery 和 OuterRef**
- 在資料庫層面執行子查詢
- 避免在 Python 層面進行複雜的資料處理

**2. 使用 annotate() 和 aggregate()**
- 在資料庫層面進行聚合計算
- 減少資料傳輸和應用層計算

**3. 使用 Raw SQL 或 extra()**
- 對於極度複雜的查詢，可考慮使用原生 SQL
- `extra()` 允許注入 SQL 片段（但已被棄用，建議使用其他方法）

**4. 查詢結果緩存**
- 使用 Django 的緩存框架（Redis、Memcached）
- 緩存頻繁訪問但變化不大的查詢結果

### 常見陷阱

**1. 過度優化**
- 不要預先載入不需要的資料
- `select_related()` 和 `prefetch_related()` 會增加初始查詢的複雜度

**2. 不當的切片使用**
- 切片會限制 SQL 的 LIMIT 和 OFFSET
- 深度分頁（大 OFFSET）性能較差

**3. 在循環中執行查詢**
- 永遠要避免在循環內執行資料庫操作
- 使用批量操作或預取關聯資料

## 最佳實踐總結

1. **識別性能瓶頸**：使用 Django Debug Toolbar 監控查詢
2. **解決 N+1 問題**：合理使用 `select_related()` 和 `prefetch_related()`
3. **減少資料傳輸**：使用 `only()`、`defer()`、`values()` 限制欄位
4. **批量操作**：使用 `bulk_create()`、`bulk_update()` 等批量方法
5. **建立索引**：為頻繁查詢的欄位建立適當索引
6. **使用緩存**：緩存頻繁訪問的查詢結果
7. **資料庫層計算**：使用 `annotate()`、`aggregate()` 在資料庫層面處理資料
