# 向量嵌入 (Embeddings) 原理

- **難度**: 6
- **標籤**: `Embeddings`, `向量化`, `語義理解`, `NLP`

## 問題詳述

向量嵌入（Vector Embeddings）是將文本、圖片、音頻等非結構化資料轉換為高維向量的技術，是實現語義搜尋、RAG、推薦系統的基礎。理解 Embedding 的原理、選擇合適的模型，以及優化 Embedding 的生成和使用，是構建 AI 應用的核心技能。

## 核心理論與詳解

### 什麼是向量嵌入

**向量嵌入（Embedding）** 是將高維、稀疏的資料（如文本、圖片）映射到低維、稠密的向量空間的過程。在這個向量空間中，語義相似的物件會彼此靠近。

**簡單類比**：
```
文本：「貓」
↓ Embedding 模型
向量：[0.2, 0.8, 0.1, ..., 0.3]（1536維）

文本：「小貓」
↓ Embedding 模型
向量：[0.21, 0.79, 0.12, ..., 0.31]（1536維）

兩個向量很接近（語義相似）
```

**核心概念**：
1. **語義捕捉**：相似意義的詞彙/句子在向量空間中接近
2. **維度降低**：從數萬維（詞彙表大小）降到幾百維
3. **稠密表示**：大部分維度都有非零值（vs One-Hot 編碼）
4. **連續空間**：可以進行數學運算（相似度、聚類）

### 傳統編碼 vs Embedding

#### 1. One-Hot 編碼（傳統方法）

```
詞彙表：["貓", "狗", "魚", "鳥"]

"貓" → [1, 0, 0, 0]
"狗" → [0, 1, 0, 0]
"魚" → [0, 0, 1, 0]
```

**問題**：
- 維度等於詞彙表大小（通常數萬到數十萬）
- 稀疏（大部分是 0）
- 無法表示語義關係（"貓" 和 "狗" 同樣遠離）
- 無法處理未見過的詞

#### 2. Embedding（現代方法）

```
"貓" → [0.2, 0.8, 0.1, ..., 0.3]（384-1536維）
"狗" → [0.22, 0.78, 0.09, ..., 0.32]
"魚" → [0.15, 0.65, 0.25, ..., 0.4]

相似度：
cos("貓", "狗") = 0.95（高相似）
cos("貓", "魚") = 0.75（中等相似）
```

**優勢**：
- 維度固定且較小（384-3072）
- 稠密（所有維度都有意義）
- 捕捉語義關係
- 可以泛化到未見過的詞組合

## 常見面試問題

### 1. 解釋向量嵌入的原理和優勢

**答案要點**：
- 將離散、高維資料轉換為連續、低維向量
- 捕捉語義關係，相似物件在向量空間中接近
- 優於 One-Hot 編碼（稠密、維度低、有語義）
- 可進行數學運算（相似度、聚類、降維）

### 2. 如何選擇 Embedding 模型？

**答案要點**：
- **語言支援**：單語言 vs 多語言
- **維度**：影響精度和成本（384-3072）
- **上下文長度**：模型能處理的最大 tokens
- **成本**：API 費用（OpenAI）vs 自建（開源）
- **質量**：在具體任務上的表現（需測試）

### 3. 餘弦相似度和歐幾里得距離的區別？

**答案要點**：
- **餘弦相似度**：只考慮方向，忽略大小，範圍 [-1, 1]
- **歐幾里得距離**：考慮實際距離，範圍 [0, ∞]
- **使用場景**：文本通常用餘弦（因為 Embedding 已歸一化），圖片可用歐幾里得
- **計算效率**：歸一化向量用點積最快

### 4. 如何處理長文檔的 Embedding？

**答案要點**：
- **截斷**：只取前 N 個 tokens（簡單但損失資訊）
- **分塊聚合**：分成多個塊，分別 Embedding 後平均
- **長上下文模型**：使用支援長文本的模型（8K+ tokens）
- **層次化**：先 Embedding 段落，再 Embedding 段落摘要

### 5. 如何優化 Embedding 生成的成本？

**答案要點**：
- **快取**：相同文本不重複生成
- **批次處理**：批量調用 API
- **模型選擇**：根據需求選擇合適維度的模型
- **增量更新**：只對新內容或變更內容生成
- **自建模型**：長期大量使用考慮自建

## 總結

向量嵌入是 AI 應用的基礎：

1. **理解原理**：從 One-Hot 到現代 Transformer-based Embedding
2. **模型選擇**：根據語言、維度、成本選擇合適模型
3. **實施技巧**：分塊、快取、批次處理
4. **質量評估**：使用 Recall、MRR 等指標
5. **持續優化**：監控質量、成本，迭代改進

掌握 Embedding 技術是構建語義搜尋、RAG、推薦系統的前提。

## 延伸閱讀

- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Sentence Transformers Documentation](https://www.sbert.net/)
- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
- [Understanding Vector Embeddings](https://www.pinecone.io/learn/vector-embeddings/)
