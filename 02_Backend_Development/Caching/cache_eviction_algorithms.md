# 快取淘汰演算法詳解

- **難度**: 6
- **重要程度**: 5
- **標籤**: `LRU`, `LFU`, `FIFO`, `Cache Eviction`, `Algorithm`

## 問題詳述

當快取空間滿載時,需要選擇合適的淘汰演算法來移除部分資料,為新資料騰出空間。請詳細解釋常見的快取淘汰演算法 (如 LRU、LFU、FIFO 等),並說明它們的實現原理、適用場景以及優缺點。

## 核心理論與詳解

快取淘汰演算法 (Cache Eviction Algorithm) 決定了當快取容量達到上限時,應該移除哪些資料。一個好的淘汰演算法應該能夠保留最有價值的資料,從而維持較高的快取命中率。

### 為什麼需要快取淘汰

快取通常使用記憶體儲存,而記憶體資源有限且昂貴。當快取空間被填滿時,必須根據某種策略決定淘汰哪些資料:

- **記憶體限制**: 無法無限擴充快取容量
- **成本考量**: 記憶體成本遠高於磁碟
- **效能優化**: 保留熱點資料,提高命中率
- **資料時效性**: 移除過期或不再使用的資料

### 常見快取淘汰演算法

#### 1. FIFO (First In First Out)

**原理**: 先進先出,最早放入快取的資料最先被淘汰。

**實現方式**:
- 使用佇列 (Queue) 資料結構
- 新資料加入隊尾
- 淘汰時從隊頭移除

**時間複雜度**:
- 插入: O(1)
- 查詢: O(n)
- 淘汰: O(1)

**優點**:
- 實現極為簡單
- 記憶體開銷小
- 公平性好,按時間順序處理

**缺點**:
- **無法識別熱點資料**: 即使某個資料經常被訪問,只要它是最早進入的,就會被淘汰
- 命中率通常較低
- 不適合實際生產環境

**適用場景**:
- 對命中率要求不高的場景
- 資料訪問模式完全隨機的場景
- 教學示範或原型開發

**示例**:

```text
快取容量: 3
訪問序列: A, B, C, D, E

時間 | 操作 | 快取狀態 | 命中/未命中
-----|------|---------|------------
1    | A    | [A]     | 未命中
2    | B    | [A,B]   | 未命中
3    | C    | [A,B,C] | 未命中
4    | D    | [B,C,D] | 未命中 (淘汰 A)
5    | E    | [C,D,E] | 未命中 (淘汰 B)
```

#### 2. LRU (Least Recently Used)

**原理**: 淘汰**最久未使用**的資料。基於局部性原理 (Locality of Reference),最近使用過的資料很可能在近期再次被使用。

**核心思想**: 維護一個按訪問時間排序的資料結構,每次訪問時更新資料的位置。

**實現方式一: 雙向鏈結串列 + 哈希表**

```text
結構:
- 雙向鏈結串列: 維護訪問順序 (頭部=最新,尾部=最舊)
- 哈希表: 快速定位節點位置

操作:
1. GET(key):
   - 從哈希表查找節點
   - 將節點移到鏈結串列頭部
   - 返回 value
   
2. PUT(key, value):
   - 如果 key 存在: 更新 value,移到頭部
   - 如果 key 不存在:
     * 如果快取已滿: 刪除尾部節點
     * 新增節點到頭部
```

**時間複雜度**:
- 插入: O(1)
- 查詢: O(1)
- 淘汰: O(1)

**空間複雜度**: O(n) - 需要額外的鏈結串列和哈希表

**實現範例 (概念性)**:

```go
// Go 語言示例: LRU Cache 實現

// LRU 節點
type Node struct {
    key   string
    value interface{}
    prev  *Node
    next  *Node
}

// LRU Cache 結構
type LRUCache struct {
    capacity int
    cache    map[string]*Node
    head     *Node  // 虛擬頭節點 (最新)
    tail     *Node  // 虛擬尾節點 (最舊)
}

// 初始化 LRU Cache
func NewLRUCache(capacity int) *LRUCache {
    lru := &LRUCache{
        capacity: capacity,
        cache:    make(map[string]*Node),
        head:     &Node{},
        tail:     &Node{},
    }
    lru.head.next = lru.tail
    lru.tail.prev = lru.head
    return lru
}

// 移動節點到頭部 (標記為最近使用)
func (lru *LRUCache) moveToHead(node *Node) {
    lru.removeNode(node)
    lru.addToHead(node)
}

// 從鏈結串列移除節點
func (lru *LRUCache) removeNode(node *Node) {
    node.prev.next = node.next
    node.next.prev = node.prev
}

// 新增節點到頭部
func (lru *LRUCache) addToHead(node *Node) {
    node.next = lru.head.next
    node.prev = lru.head
    lru.head.next.prev = node
    lru.head.next = node
}

// 移除尾部節點 (淘汰最久未使用)
func (lru *LRUCache) removeTail() *Node {
    node := lru.tail.prev
    lru.removeNode(node)
    return node
}

// 獲取資料
func (lru *LRUCache) Get(key string) (interface{}, bool) {
    if node, exists := lru.cache[key]; exists {
        // 將節點移到頭部 (標記為最近使用)
        lru.moveToHead(node)
        return node.value, true
    }
    return nil, false
}

// 寫入資料
func (lru *LRUCache) Put(key string, value interface{}) {
    if node, exists := lru.cache[key]; exists {
        // key 已存在,更新 value 並移到頭部
        node.value = value
        lru.moveToHead(node)
    } else {
        // key 不存在,建立新節點
        newNode := &Node{key: key, value: value}
        lru.cache[key] = newNode
        lru.addToHead(newNode)
        
        // 如果超過容量,淘汰尾部節點
        if len(lru.cache) > lru.capacity {
            removed := lru.removeTail()
            delete(lru.cache, removed.key)
        }
    }
}
```

**優點**:
- **符合局部性原理**: 最近使用的資料很可能再次被使用
- 命中率通常較高
- 適用於大多數場景

**缺點**:
- **無法應對偶發性熱點**: 如果某個資料被大量訪問一次後不再訪問,仍會佔據快取空間
- **空間開銷**: 需要維護鏈結串列和哈希表
- **寫入開銷**: 每次訪問都需要移動節點

**適用場景**:
- 一般的 Web 應用快取
- 資料庫查詢結果快取
- 頁面快取、API 回應快取

**示例**:

```text
快取容量: 3
訪問序列: A, B, C, A, D

時間 | 操作 | 快取狀態 (左=最新) | 命中/未命中
-----|------|-------------------|------------
1    | A    | [A]               | 未命中
2    | B    | [B,A]             | 未命中
3    | C    | [C,B,A]           | 未命中
4    | A    | [A,C,B]           | 命中 (A 移到最前)
5    | D    | [D,A,C]           | 未命中 (淘汰 B)
```

#### 3. LFU (Least Frequently Used)

**原理**: 淘汰**訪問頻率最低**的資料。認為訪問頻率高的資料在未來更有可能被訪問。

**核心思想**: 為每個資料維護一個訪問計數器,淘汰時選擇計數最小的資料。

**實現方式**: 哈希表 + 最小堆 或 哈希表 + 頻率鏈結串列

**結構設計**:

```text
方案一: 哈希表 + 最小堆
- 哈希表: key → (value, frequency)
- 最小堆: 按 frequency 排序
- 淘汰: 彈出堆頂元素

方案二: 哈希表 + 頻率桶 (更優)
- 哈希表: key → Node
- 頻率桶: frequency → 雙向鏈結串列
- minFreq: 記錄當前最小頻率
```

**時間複雜度**:
- 插入: O(1)
- 查詢: O(1)
- 淘汰: O(1)

**優點**:
- **能識別真正的熱點資料**: 長期高頻訪問的資料不會被淘汰
- 適合訪問模式穩定的場景

**缺點**:
- **實現複雜**: 需要維護頻率計數和多個資料結構
- **冷啟動問題**: 新加入的資料初始頻率為 1,即使是熱點資料也容易被淘汰
- **歷史數據影響**: 曾經的熱點資料頻率很高,即使現在不再訪問也難以淘汰
- **空間開銷大**: 需要儲存頻率資訊

**適用場景**:
- 訪問模式穩定的場景 (如熱門商品、文章)
- 需要長期保留高頻資料
- CDN 邊緣節點快取

**示例**:

```text
快取容量: 3
訪問序列: A, B, A, C, A, B, D

時間 | 操作 | 快取狀態 [key(freq)] | 命中/未命中
-----|------|---------------------|------------
1    | A    | [A(1)]              | 未命中
2    | B    | [A(1),B(1)]         | 未命中
3    | A    | [A(2),B(1)]         | 命中
4    | C    | [A(2),B(1),C(1)]    | 未命中
5    | A    | [A(3),B(1),C(1)]    | 命中
6    | B    | [A(3),B(2),C(1)]    | 命中
7    | D    | [A(3),B(2),D(1)]    | 未命中 (淘汰 C,freq=1)
```

#### 4. LRU-K (LRU-2, LRU-3 等)

**原理**: LRU 的改進版,記錄資料**最近 K 次訪問的時間**,根據第 K 次訪問時間進行淘汰。

**核心思想**: 解決 LRU 的「偶發性訪問」問題,避免將偶然訪問一次的資料長時間保留。

**運作方式**:
- 維護每個資料的訪問歷史 (記錄最近 K 次訪問時間)
- 淘汰時,選擇第 K 次訪問時間最早的資料
- 如果訪問次數不足 K 次,優先淘汰

**LRU-2 示例**:

```text
快取容量: 3
K = 2 (記錄最近 2 次訪問)

訪問序列: A, B, C, A, D

時間 | 操作 | 訪問歷史              | 淘汰決策
-----|------|----------------------|----------
1    | A    | A[1]                 | -
2    | B    | A[1], B[2]           | -
3    | C    | A[1], B[2], C[3]     | -
4    | A    | A[1,4], B[2], C[3]   | -
5    | D    | A[1,4], D[5], C[3]   | 淘汰 B (只訪問 1 次)
```

**優點**:
- 解決偶發性訪問問題
- 更精準識別熱點資料
- 提高命中率

**缺點**:
- 實現更複雜
- 空間開銷更大 (需記錄 K 次訪問歷史)
- K 值需要根據場景調優

**適用場景**:
- 存在大量偶發性訪問的場景
- 對命中率要求極高的系統

#### 5. Two Queue (2Q)

**原理**: 使用兩個佇列來區分「短期訪問」和「長期訪問」的資料。

**結構設計**:

```text
FIFO 佇列 (A1): 存放首次訪問的資料 (試用期)
LRU 佇列 (Am): 存放多次訪問的資料 (正式快取)

流程:
1. 新資料進入 A1 (FIFO)
2. A1 中的資料被再次訪問 → 移入 Am (LRU)
3. A1 滿時,淘汰最早進入的資料
4. Am 滿時,按 LRU 淘汰
```

**優點**:
- 結合 FIFO 和 LRU 的優點
- 有效過濾偶發性訪問
- 保護長期熱點資料

**缺點**:
- 實現複雜
- 需要調整兩個佇列的容量比例
- 記憶體開銷較大

**適用場景**:
- 混合訪問模式的場景
- 需要區分短期和長期熱點

#### 6. ARC (Adaptive Replacement Cache)

**原理**: 自適應演算法,動態平衡「最近訪問」(LRU) 和「頻繁訪問」(LFU) 的權重。

**核心特點**:
- 維護四個鏈結串列: T1, T2, B1, B2
- 根據訪問模式自動調整快取策略
- 無需人工調參

**優點**:
- 自適應,適應不同的訪問模式
- 理論命中率接近最優

**缺點**:
- 實現非常複雜
- 記憶體開銷大
- 有專利限制 (IBM)

**適用場景**:
- 訪問模式變化劇烈的場景
- 高端儲存系統

#### 7. Random (隨機淘汰)

**原理**: 隨機選擇一個資料進行淘汰。

**優點**:
- 實現極為簡單
- 無額外記憶體開銷
- 無鎖爭用問題

**缺點**:
- 命中率低
- 不可預測

**適用場景**:
- 原型開發
- 對命中率要求不高的場景
- 簡化測試環境

### Redis 的淘汰策略

Redis 提供了 8 種淘汰策略,可通過 `maxmemory-policy` 配置:

#### 1. noeviction (預設)

- **行為**: 當記憶體達到上限時,拒絕所有寫入操作,只允許讀取和刪除
- **適用**: 不希望丟失任何資料的場景

#### 2. allkeys-lru

- **行為**: 對所有 key 使用 LRU 演算法淘汰
- **適用**: 通用場景,最常用的策略

#### 3. allkeys-lfu (Redis 4.0+)

- **行為**: 對所有 key 使用 LFU 演算法淘汰
- **適用**: 明確的熱點資料場景

#### 4. allkeys-random

- **行為**: 隨機淘汰任意 key
- **適用**: 所有 key 訪問頻率相近的場景

#### 5. volatile-lru

- **行為**: 對設定了過期時間的 key 使用 LRU 淘汰
- **適用**: 區分永久資料和臨時資料

#### 6. volatile-lfu (Redis 4.0+)

- **行為**: 對設定了過期時間的 key 使用 LFU 淘汰
- **適用**: 有明確過期時間的熱點資料

#### 7. volatile-random

- **行為**: 隨機淘汰設定了過期時間的 key
- **適用**: 過期 key 均等重要的場景

#### 8. volatile-ttl

- **行為**: 優先淘汰 TTL 最短的 key
- **適用**: 希望優先移除即將過期的資料

**配置示例**:

```bash
# redis.conf 配置

# 設定最大記憶體限制 (如 2GB)
maxmemory 2gb

# 設定淘汰策略
maxmemory-policy allkeys-lru

# LFU 相關配置 (Redis 4.0+)
lfu-log-factor 10       # 頻率計數器增長速度
lfu-decay-time 1        # 頻率衰減時間 (分鐘)
```

### 演算法對比總結

| 演算法 | 時間複雜度 | 空間複雜度 | 命中率 | 實現難度 | 適用場景 |
|--------|-----------|-----------|--------|---------|---------|
| **FIFO** | O(1) | O(n) | 低 | 簡單 | 教學、原型 |
| **LRU** | O(1) | O(n) | 較高 | 中等 | 通用場景 ⭐ |
| **LFU** | O(1) | O(n) | 高 | 複雜 | 穩定熱點 |
| **LRU-K** | O(1) | O(kn) | 很高 | 複雜 | 高要求場景 |
| **2Q** | O(1) | O(n) | 高 | 複雜 | 混合訪問模式 |
| **ARC** | O(1) | O(n) | 最高 | 非常複雜 | 自適應場景 |
| **Random** | O(1) | O(n) | 低 | 極簡單 | 低要求場景 |

### 如何選擇淘汰演算法

#### 選擇因素

1. **訪問模式**:
   - 時間局部性強 → LRU
   - 明確的熱點資料 → LFU
   - 偶發性訪問多 → LRU-K 或 2Q

2. **效能要求**:
   - 高吞吐量 → LRU (實現簡單,開銷小)
   - 高命中率 → LFU 或 LRU-K

3. **實現複雜度**:
   - 快速實現 → FIFO 或 LRU
   - 不介意複雜度 → LFU、2Q、ARC

4. **記憶體預算**:
   - 記憶體充足 → LRU-K、2Q (空間換命中率)
   - 記憶體緊張 → LRU (開銷較小)

#### 實務建議

**通用 Web 應用**: 使用 LRU (Redis 的 `allkeys-lru`)
- 實現成熟,效能穩定
- 命中率足夠高
- 維護成本低

**明確熱點場景**: 使用 LFU (Redis 的 `allkeys-lfu`)
- 電商熱門商品
- 新聞熱點文章
- 視頻平台熱門內容

**混合場景**: 分層快取
- L1 本地快取: LRU (容量小,速度快)
- L2 分散式快取: LFU (容量大,保留長期熱點)

### 常見面試考點

#### Q1: LRU 和 LFU 的區別是什麼?各適用什麼場景?

**答案**:
- **LRU (最近最少使用)**: 淘汰最久未訪問的資料,適合時間局部性強的場景 (如一般 Web 應用)
- **LFU (最少使用頻率)**: 淘汰訪問頻率最低的資料,適合明確的熱點資料場景 (如熱門商品、文章)

**關鍵差異**: LRU 關注「最近」,LFU 關注「頻率」。LRU 可能因為偶然訪問而保留冷門資料,LFU 可能因為歷史高頻而保留不再熱門的資料。

#### Q2: 如何實現一個 LRU Cache?

**答案**: 使用**雙向鏈結串列 + 哈希表**:
- 雙向鏈結串列: 維護訪問順序 (頭部最新,尾部最舊)
- 哈希表: 快速定位節點 (O(1) 查詢)

**操作**:
- GET: 查找節點 → 移到頭部 → 返回 value
- PUT: 如果存在則更新並移到頭部;如果不存在則新增到頭部,容量滿時刪除尾部

**時間複雜度**: 所有操作都是 O(1)

#### Q3: Redis 的 LRU 是精確的 LRU 嗎?

**答案**: **不是**。Redis 使用**近似 LRU** (Approximate LRU) 來減少記憶體開銷:
- 不維護完整的鏈結串列
- 在每個 key 上記錄最後訪問時間戳 (24 bits)
- 淘汰時隨機採樣 5 個 (可配置) key,淘汰其中最舊的

**優點**: 記憶體開銷小,效能高
**缺點**: 不是絕對精確,但在實務中效果已經很好

#### Q4: LFU 的「冷啟動問題」和「歷史數據問題」如何解決?

**答案**:

**冷啟動問題** (新資料初始頻率低,容易被淘汰):
- 設定初始頻率為一個較高值 (如 5)
- 使用「窗口期保護」,新資料在一段時間內不被淘汰

**歷史數據問題** (舊的高頻資料難以淘汰):
- **頻率衰減**: 定期將所有資料的頻率減半或減少固定值
- **時間窗口**: 只統計最近一段時間的訪問頻率
- **Redis 方案**: 使用 Morris 計數器 + 時間衰減因子

#### Q5: 什麼場景下使用 Random 淘汰策略?

**答案**:
- **所有資料訪問頻率相近**: 沒有明顯的熱點資料
- **快速原型開發**: 實現簡單,快速驗證想法
- **低要求場景**: 對命中率要求不高
- **避免鎖競爭**: Random 無需複雜的資料結構,併發效能好

### 總結

快取淘汰演算法的選擇取決於業務場景和效能要求:

1. **通用場景**: LRU 是最佳選擇,實現簡單且命中率高
2. **明確熱點**: LFU 能更好地保留高頻資料
3. **高要求場景**: 考慮 LRU-K 或 2Q,但實現複雜度更高
4. **自適應需求**: ARC 可自動調整策略,但實現非常複雜

**實務建議**: 絕大多數場景下,Redis 的 `allkeys-lru` 策略已經足夠好。除非有明確的特殊需求,否則不需要使用更複雜的演算法。記住:**簡單可靠勝過複雜精巧**。
