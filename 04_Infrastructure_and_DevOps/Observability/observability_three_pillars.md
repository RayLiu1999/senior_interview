# 什麼是可觀測性三大支柱（Metrics、Logs、Traces）？

- **難度**: 4
- **重要程度**: 5
- **標籤**: `可觀測性`, `監控`, `日誌`, `追蹤`, `Metrics`, `Logs`, `Traces`

## 問題詳述

可觀測性（Observability）是現代分散式系統的核心能力，它由三個互補的支柱組成：Metrics（指標）、Logs（日誌）和 Traces（追蹤）。理解這三者的定義、差異和互補關係，是構建可靠系統的基礎。

## 核心理論與詳解

### 可觀測性的定義

**可觀測性（Observability）** 是指從系統的外部輸出推斷其內部狀態的能力。在軟體工程中，可觀測性讓工程師能夠：

- **理解系統行為**：知道系統正在做什麼
- **發現異常**：快速識別問題
- **定位根因**：找到問題的真正原因
- **優化效能**：識別瓶頸並改進

可觀測性由三大支柱支撐，它們從不同維度提供系統洞察：

---

### 支柱一：Metrics（指標）

#### 什麼是 Metrics？

**Metrics（指標）** 是對系統狀態的**數值化度量**，通常是聚合的時間序列資料。它回答的是「發生了多少次？」「當前值是多少？」

#### 核心特徵

- **數值型資料**：CPU 使用率、記憶體用量、請求數、錯誤率等
- **時間序列**：按時間順序記錄的數值點
- **聚合性**：通常是多個事件的統計結果（如平均值、總和、百分位數）
- **高效儲存**：佔用空間小，適合長期保存

#### 常見指標類型

1. **Counter（計數器）**：只增不減的累計值
   - 範例：HTTP 請求總數、錯誤次數
   
2. **Gauge（儀表盤）**：可增可減的瞬時值
   - 範例：當前記憶體使用量、連線數
   
3. **Histogram（直方圖）**：觀察值的分布
   - 範例：請求延遲分布、請求大小分布
   
4. **Summary（摘要）**：類似 Histogram，但計算百分位數
   - 範例：P50、P95、P99 延遲

#### 典型應用場景

- **即時監控**：系統健康狀態一覽
- **容量規劃**：資源使用趨勢分析
- **告警觸發**：當指標超過閾值時發送告警
- **效能分析**：識別系統瓶頸

#### 代表工具

- **Prometheus**：業界最流行的開源時序資料庫
- **Grafana**：視覺化儀表板
- **StatsD**：指標聚合服務
- **CloudWatch**、**Datadog**：雲端監控服務

---

### 支柱二：Logs（日誌）

#### 什麼是 Logs？

**Logs（日誌）** 是系統產生的**離散事件記錄**，描述系統在特定時間點發生了什麼事情。它回答的是「發生了什麼？」「為什麼發生？」

#### 核心特徵

- **事件驅動**：每個日誌條目代表一個事件
- **文字或結構化資料**：可以是純文字或 JSON 等格式
- **詳細的上下文**：包含時間、日誌等級、訊息、堆疊追蹤等
- **儲存成本高**：資料量大，通常只保留有限時間

#### 日誌等級（Log Levels）

1. **TRACE/DEBUG**：詳細的除錯資訊
2. **INFO**：一般資訊事件（如「用戶登入成功」）
3. **WARN**：警告但不影響正常運作
4. **ERROR**：錯誤事件但系統仍可繼續運作
5. **FATAL/CRITICAL**：嚴重錯誤導致系統停止

#### 結構化日誌 vs 非結構化日誌

**非結構化日誌**（傳統方式）：
```
2024-01-15 10:23:45 ERROR Failed to connect to database: connection timeout
```

**結構化日誌**（現代最佳實踐）：
```json
{
  "timestamp": "2024-01-15T10:23:45Z",
  "level": "ERROR",
  "message": "Failed to connect to database",
  "error": "connection timeout",
  "service": "user-service",
  "trace_id": "abc123",
  "user_id": "user_456"
}
```

結構化日誌的優勢：
- **易於查詢**：可以精確搜尋特定欄位
- **易於分析**：支援聚合和統計
- **易於關聯**：可以通過 trace_id 關聯到追蹤資料

#### 典型應用場景

- **問題除錯**：查看錯誤的詳細上下文
- **安全審計**：追蹤用戶行為和系統變更
- **業務分析**：分析用戶行為模式
- **合規性**：滿足法規要求的記錄保留

#### 代表工具

- **ELK Stack**（Elasticsearch、Logstash、Kibana）
- **Loki**（Grafana Labs 開發，類似 Prometheus 的日誌系統）
- **Fluentd**：開源日誌收集器
- **Splunk**：商業日誌分析平台

---

### 支柱三：Traces（追蹤）

#### 什麼是 Traces？

**Traces（追蹤）** 記錄一個**請求在分散式系統中的完整生命週期路徑**。它回答的是「請求經過了哪些服務？」「在哪裡花費了時間？」

#### 核心概念

1. **Trace（追蹤）**：一個完整的請求流程
2. **Span（跨度）**：追蹤中的一個操作單元
3. **Parent Span & Child Span**：Span 之間的層級關係
4. **Context Propagation**：跨服務邊界傳遞追蹤上下文

#### Trace 的結構

一個典型的分散式追蹤如下：

```
Trace ID: abc123

[Span 1] API Gateway         (100ms)
  └─[Span 2] User Service     (30ms)
      └─[Span 3] DB Query     (20ms)
  └─[Span 4] Order Service    (50ms)
      └─[Span 5] Cache Read   (5ms)
      └─[Span 6] DB Query     (40ms)
```

每個 Span 包含：
- **Span ID**：唯一識別碼
- **Parent Span ID**：父 Span 的 ID
- **Operation Name**：操作名稱（如「HTTP GET /users」）
- **Start Time & Duration**：開始時間和持續時間
- **Tags**：鍵值對元資料（如 http.method=GET）
- **Logs**：Span 內的事件日誌

#### 核心特徵

- **因果關係**：展示請求在服務間的調用順序
- **效能分析**：識別延遲的來源
- **依賴關係**：理解服務間的依賴
- **取樣**：通常只追蹤部分請求（如 1%-10%）以降低開銷

#### 典型應用場景

- **效能優化**：找出哪個服務或操作最慢
- **依賴分析**：理解服務拓撲關係
- **根因分析**：快速定位分散式系統中的問題
- **SLA 監控**：追蹤端到端的請求延遲

#### 代表工具

- **Jaeger**：Uber 開源的分散式追蹤系統
- **Zipkin**：Twitter 開源的追蹤系統
- **OpenTelemetry**：統一的可觀測性框架（標準化 API）
- **AWS X-Ray**、**Google Cloud Trace**：雲端原生追蹤服務

---

### 三大支柱的對比

| 特性 | Metrics | Logs | Traces |
|------|---------|------|--------|
| **資料類型** | 數值型時間序列 | 離散事件記錄 | 請求的調用鏈 |
| **回答的問題** | 發生了多少？趨勢如何？ | 發生了什麼？為什麼？ | 請求如何流轉？在哪慢？ |
| **資料量** | 小（聚合） | 大（每個事件） | 中（取樣） |
| **保留時間** | 長（數月到數年） | 中（數天到數週） | 短（數天） |
| **查詢速度** | 非常快 | 中等 | 快 |
| **典型用途** | 監控、告警 | 除錯、審計 | 效能分析、根因定位 |
| **適合分析** | 趨勢、異常檢測 | 詳細上下文 | 依賴關係、延遲來源 |

---

### 三大支柱的互補關係

這三者並非獨立存在，而是**互相補充**的：

#### 場景一：告警觸發後的問題定位

1. **Metrics 告警**：CPU 使用率突然飆升到 90%（發現異常）
2. **Logs 查詢**：查看錯誤日誌，發現某個 API 端點大量報錯（找到症狀）
3. **Traces 分析**：追蹤該 API 的請求鏈路，發現資料庫查詢耗時過長（定位根因）

#### 場景二：從用戶報錯到解決問題

1. **Logs**：用戶報錯「訂單創建失敗」，從日誌中找到錯誤訊息和 trace_id
2. **Traces**：通過 trace_id 找到完整的請求鏈路，發現是庫存服務超時
3. **Metrics**：查看庫存服務的監控指標，發現記憶體不足導致 GC 頻繁

#### 關聯的關鍵：Trace ID

在實踐中，通常會在日誌中記錄 **trace_id**，這樣可以：
- 從日誌跳轉到追蹤資料
- 從追蹤跳轉到相關日誌
- 結合指標快速定位問題

---

### 實踐建議

#### 1. 統一的可觀測性策略

- 所有服務應該一致地實現三大支柱
- 使用統一的標準（如 OpenTelemetry）
- 建立跨團隊的可觀測性規範

#### 2. 關鍵字段設計

確保以下欄位在三大支柱中保持一致：
- **trace_id**：請求的唯一識別碼
- **service_name**：服務名稱
- **environment**：環境（production、staging 等）
- **timestamp**：時間戳記

#### 3. 平衡成本與價值

- **Metrics**：全量採集，成本低
- **Logs**：選擇性記錄，僅記錄有價值的事件
- **Traces**：取樣採集（1%-10%），特別慢的請求可以提高取樣率

#### 4. 工具選型考量

| 考量因素 | Metrics | Logs | Traces |
|---------|---------|------|--------|
| **開源方案** | Prometheus + Grafana | ELK/Loki | Jaeger/Zipkin |
| **雲端方案** | CloudWatch/Datadog | CloudWatch Logs | AWS X-Ray |
| **統一方案** | OpenTelemetry | OpenTelemetry | OpenTelemetry |

---

### 常見面試問題

#### Q1：為什麼需要三個支柱而不是只用一個？

**回答要點**：
- 每個支柱關注不同的維度，提供互補的洞察
- Metrics 適合快速發現異常和趨勢分析
- Logs 適合提供詳細的上下文和除錯資訊
- Traces 適合理解分散式系統中的因果關係
- 三者結合才能快速定位和解決問題

#### Q2：如何在微服務架構中實現可觀測性？

**回答要點**：
- 使用統一的 SDK 或框架（如 OpenTelemetry）
- 在服務間傳遞 trace_id（通常通過 HTTP Header）
- 集中式收集和儲存可觀測性資料
- 建立統一的視覺化和查詢界面
- 設計合理的告警和事件響應流程

#### Q3：可觀測性資料的成本很高，如何優化？

**回答要點**：
- **Metrics**：使用適當的保留策略和降採樣
- **Logs**：只記錄必要的日誌等級（生產環境避免 DEBUG）
- **Traces**：使用取樣策略，錯誤和慢請求可以提高取樣率
- 使用資料分級儲存（熱資料 vs 冷資料）
- 定期審查和優化可觀測性配置

---

## 總結

可觀測性三大支柱是現代後端系統的基礎設施，它們各有側重但互相補充：

- **Metrics（指標）**：快速發現問題的「雷達」
- **Logs（日誌）**：詳細記錄的「黑盒子」
- **Traces（追蹤）**：分散式系統的「導航地圖」

在實踐中，成功的可觀測性策略需要：
1. **統一標準**：使用一致的工具和規範
2. **關聯資料**：通過 trace_id 等關鍵字段關聯三大支柱
3. **平衡成本**：根據價值選擇性採集資料
4. **持續優化**：根據實際問題不斷改進可觀測性實踐

掌握這三大支柱，是成為資深後端工程師的必備技能，也是面試中的高頻考點。
